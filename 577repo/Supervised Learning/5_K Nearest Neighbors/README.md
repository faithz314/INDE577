# K Nearest Neighbors

Love thy neighbors, they say! We have now made it to my favorite ML algorithm (totally not biased because of its simplicity). KNN is simple, but a widely used algorithm simply because of its simplicty (haha see what I did there).

This ML model is also used for both classification and regressin tasks, and it operates under the assumption similar data points tend to belong to the same class or tend to have similar output values. 

KNN is definitely not the most computationally complex, but it's fun to manipulate different parameters within the model: the k number of neighbors you would like to consider, the type of distance you want to calculate, and so on.

After all, birds of a feather flock together! In this notebook, we will be analyzing future grades using this method.
